---
category: NLP
path: '/stuff/:id'
title: '문장 수준 임베딩'
type: 'NLP'

layout: nil
---

# 문장 수준 임베딩

1. 행렬 분해 : LSA
2. 확률 모델 : LDA
3. 뉴럴 네트워크 기반 모델 : Doc2Vec, ELMo, GPT, BERT (셀프 어텐션 기반의 트랜스포머 네트워크)

***

## LSA (잠재 의미 분석)

- ...

***

## LDA (잠재 디리클레 할당)

- ...

***

## Doc2Vec

- 2014년 구글 연구팀이 개발한 문서 임베딩 기법이다.
- 이전 단어 시쿼스 K개가 주어졌을 때 그 다음 단어를 맞추는 언어 모델이다.

***

## ELMo (Embeddings from Language Models)

- 2018년 미국 연구 기관 앨런에이아이와 미국 워싱턴대학교 공동연구팀이 발표한 문장 임베딩 기법이다.
- 컴퓨터 비전 분야에서 널리 쓰이고 있었던 전이 학습을 자연어 처리에 접목해 주목받았다.
- 프리트레인 한 뒤 이를 각종 다운스트림 태스크에 적용하는 양상이 일반화 (BERT, GPT)
- 프리트레인한 모델을 다운스트림 태스크에 맞게 업데이트하는 과정을 파인 튜닝 이라고 한다.

### 문자 단위 컨볼루션 레이어

- 내용입력
- 내용입력
